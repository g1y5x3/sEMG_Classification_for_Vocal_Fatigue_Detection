{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e2ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tsai.all import *\n",
    "from fastai.callback.wandb import *\n",
    "from visualization_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292feded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os             : Linux-5.11.0-38-generic-x86_64-with-debian-bullseye-sid\n",
      "python         : 3.7.12\n",
      "tsai           : 0.3.1\n",
      "fastai         : 2.6.3\n",
      "fastcore       : 1.4.3\n",
      "torch          : 1.11.0+cu102\n",
      "device         : 4 gpus (['NVIDIA GeForce RTX 2080 Ti', 'NVIDIA GeForce RTX 2080 Ti', 'NVIDIA GeForce RTX 2080 Ti', 'NVIDIA GeForce RTX 2080 Ti'])\n",
      "cpu cores      : 16\n",
      "RAM            : 62.49 GB\n",
      "GPU memory     : [10.76, 10.76, 10.76, 10.76] GB\n"
     ]
    }
   ],
   "source": [
    "computer_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fcd525",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cfeffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ALL = sio.loadmat(\"subjects_40_v4.mat\")\n",
    "# DATA_ALL = sio.loadmat(\"subjects_88_v2.mat\")\n",
    "VFI_LIST = sio.loadmat(\"Notes/VFI_new_matched.mat\")\n",
    "\n",
    "VFI_1       = np.ravel(VFI_LIST['VFI1'])\n",
    "VFI_2       = np.ravel(VFI_LIST['VFI2'])\n",
    "SIG         = DATA_ALL['DATA']              # raw sEMG signals\n",
    "FEAT        = DATA_ALL['FEAT']              # Orignally calculated features\n",
    "FEAT_N      = DATA_ALL['FEAT_N']            # Normalized features\n",
    "LABEL       = DATA_ALL['LABEL']             # Labels\n",
    "SUBJECT_ID  = DATA_ALL['SUBJECT_ID']        # Sujbect ID\n",
    "LABEL_VOWEL = DATA_ALL['LABEL_VOWEL']\n",
    "VFI         = DATA_ALL['SUBJECT_VFI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0928d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "wand_config = 0\n",
    "leftout = 1\n",
    "window_length = 4000\n",
    "testing_acc = np.zeros(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2db248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Subject R085:\n",
      "VFI-1: [1]\n",
      "Left-out Test samples:  162\n",
      "Included Training samples:  0\n",
      "Train data BEFORE including:\n",
      "(6310, 4, 4000) (6310,)\n",
      "Train data AFTER including:\n",
      "(6310, 4, 4000) (6310,)\n",
      "# of Healthy Samples: 3040\n",
      "# of Fatigued Samples: 3270\n"
     ]
    }
   ],
   "source": [
    "# sub_index = [0,1,2,3,4,20,21,22,23,24]\n",
    "# for sub_test in sub_index:\n",
    "# for sub_test in range(40):\n",
    "\n",
    "sub_test = 3\n",
    "\n",
    "sub_txt = \"R%03d\"%(int(SUBJECT_ID[sub_test][0][0]))\n",
    "print('Test Subject %s:'%(sub_txt))\n",
    "print('VFI-1:', (VFI[sub_test][0][0]))\n",
    "if int(VFI[sub_test][0][0]) > 10:\n",
    "    sub_group = 'Fatigued'\n",
    "else:\n",
    "    sub_group = 'Healthy'\n",
    "\n",
    "if wand_config == 1:\n",
    "    run = wandb.init(project=\"sEMG Leave-One-Out Classification 40 0.9 Left-Out\", \n",
    "                     group=sub_group,\n",
    "                     reinit=True, \n",
    "                     name=sub_txt)\n",
    "\n",
    "# ===== Load Testing Signals =====\n",
    "num_signal = np.shape(SIG[sub_test,0])[0]    \n",
    "X_Temp = np.zeros((num_signal, 4, window_length))\n",
    "for ch in range(4):\n",
    "    X_Temp[:,ch,:] = SIG[sub_test,ch]\n",
    "\n",
    "Y_Temp = LABEL[sub_test,0].flatten()\n",
    "\n",
    "num_leftout = round(leftout*num_signal)\n",
    "index_leftout = np.random.choice(range(num_signal), size=num_leftout, replace=False)\n",
    "# index_leftout = np.random.randint(low=0, high=num_signal, size=num_leftout)\n",
    "# print(np.sort(index_leftout))\n",
    "print(\"Left-out Test samples: \", index_leftout.size)\n",
    "\n",
    "X_Test = X_Temp[index_leftout,:,:]\n",
    "Y_Test = Y_Temp[index_leftout]\n",
    "\n",
    "index_include = np.arange(num_signal)\n",
    "index_include = np.delete(index_include, index_leftout)\n",
    "# print(index_include)\n",
    "print(\"Included Training samples: \", index_include.size)\n",
    "X_include = X_Temp[index_include,:,:]\n",
    "Y_include = Y_Temp[index_include]\n",
    "\n",
    "\n",
    "# ===== Load Traing Signals =====\n",
    "X_Train = np.zeros((0,4,window_length))\n",
    "Y_Train = np.zeros(0)    \n",
    "for sub_train in range(40):\n",
    "    if sub_train != sub_test:\n",
    "        # ===== CAN BE CONVERTED INTO A FUNCTION =====            \n",
    "        num_signal = np.shape(SIG[sub_train,0])[0]\n",
    "        x_s = np.zeros((num_signal, 4, window_length))\n",
    "        for ch in range(4):\n",
    "            x_s[:,ch,:] = SIG[sub_train,ch]\n",
    "\n",
    "        y_s = LABEL[sub_train,0].flatten()\n",
    "        # ===== CAN BE CONVERTED INTO A FUNCTION =====\n",
    "\n",
    "        X_Train = np.concatenate((X_Train, x_s), axis=0)\n",
    "        Y_Train = np.concatenate((Y_Train, y_s), axis=0)\n",
    "\n",
    "print('Train data BEFORE including:')                        \n",
    "print(X_Train.shape, Y_Train.shape)\n",
    "\n",
    "X_Train = np.concatenate((X_Train, X_include), axis=0)\n",
    "Y_Train = np.concatenate((Y_Train, Y_include), axis=0)        \n",
    "\n",
    "print('Train data AFTER including:')                \n",
    "print(X_Train.shape, Y_Train.shape)\n",
    "print('# of Healthy Samples: %d'%(np.sum(Y_Train == -1)))\n",
    "print('# of Fatigued Samples: %d'%(np.sum(Y_Train == 1)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74826be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN(\n",
      "  (convblock1): ConvBlock(\n",
      "    (0): Conv1d(4, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convblock2): ConvBlock(\n",
      "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convblock3): ConvBlock(\n",
      "    (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gap): GAP1d(\n",
      "    (gap): AdaptiveAvgPool1d(output_size=1)\n",
      "    (flatten): Flatten(full=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# ===== Data loading and preprocessing =====\n",
    "# Training and Validation\n",
    "splits = get_splits(Y_Train, valid_size=.1, stratify=True, random_state=23, shuffle=True, show_plot=False)\n",
    "tfms  = [None, [Categorize()]]\n",
    "dsets = TSDatasets(X_Train, Y_Train, tfms=tfms, splits=splits)\n",
    "\n",
    "# dls = TSDataLoaders.from_dsets(dsets.train, \n",
    "#                                dsets.valid, \n",
    "#                                shuffle_train=True,\n",
    "#                                bs=32, \n",
    "#                                batch_tfms=TSStandardize(mean=dsets_mean,\n",
    "#                                                         std=dsets_std,\n",
    "#                                                         by_var=True), \n",
    "#                                num_workers=0)\n",
    "\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, \n",
    "                               dsets.valid, \n",
    "                               shuffle_train=True,\n",
    "                               bs=32, \n",
    "                               batch_tfms=TSStandardize(use_single_batch=False,\n",
    "                                                        by_var=True), \n",
    "                               num_workers=0)\n",
    "\n",
    "# dls.show_batch()\n",
    "\n",
    "# ===== FCN Classification =====\n",
    "# Need to check fastai wandb setting\n",
    "model = FCN(c_in=dls.vars, c_out=dls.c, layers=[64, 128, 64], kss=[7, 5, 3])\n",
    "print(model)\n",
    "print(dls.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88266dad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if wand_config == 1:\n",
    "    learn = Learner(dls, model, metrics=accuracy, cbs=WandbCallback())\n",
    "else:\n",
    "    learn = Learner(dls, model, metrics=accuracy)\n",
    "\n",
    "\n",
    "with learn.no_bar():\n",
    "    lr = learn.lr_find(stop_div=False, num_it=200)\n",
    "    print(\"LR fine: %.6f\"%(lr.valley))        \n",
    "    print(\"Training...\")\n",
    "    learn.fit_one_cycle(250, lr_max=0.001)\n",
    "\n",
    "# learn.recorder.plot_metrics()\n",
    "\n",
    "# the prediction returedn by the function for some reason was in string so needed to be converted.\n",
    "inp, test_probas, _, test_preds = learn.get_X_preds(X_Test, with_input=True, with_decoded=True)\n",
    "# test_probas, test_targets, test_preds\n",
    "# print(\"From get_X_preds - Input:\", inp.data)\n",
    "# print(\"From get_X_preds - Preds:\", test_probas.data)\n",
    "\n",
    "preds = np.fromstring(test_preds[1:-1], sep=',')\n",
    "print(f'Testing accuracy:{skm.accuracy_score(Y_Test, preds):10.6f}\\n\\n')\n",
    "testing_acc[sub_test] = skm.accuracy_score(Y_Test, preds)\n",
    "\n",
    "if wand_config == 1:\n",
    "    wandb.log({\"VFI-1\": int(VFI[sub_test][0][0]),\n",
    "               \"Validation Accuracy\": learn.validate()[1],\n",
    "               \"Testing Accuracy\": skm.accuracy_score(Y_Test, preds)})\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc9b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsai",
   "language": "python",
   "name": "tsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
